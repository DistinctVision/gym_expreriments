model:
  in_size: 8
  out_size: 4

  layers: [256, 128]
  dropout: 0.0
  reward_decay: 0.99

  critic_model_path: '../gym_output/dqn_10_20_2023__20_01_06/weights/lunar_lander_560.kpt'
  _critic_optimizer_path: '../gym_output/dqn_10_20_2023__01_24_57/weights/opt_critic_model_1800.kpt'

game:
  name: LunarLander-v2

replay_buffer:
  max_buffer_size: 150000
  save_every_n_step: 5
  min_episode_size: 10
  max_episode_size: 1000
  path: ../nexto_rp_0_wr.pth
  _data_dir: ../gym_output/dqn_10_19_2023__15_29_00/weights
  _cached_rnn_dir: /media/alex/SSD/rnn_cache
  _cached_rnn_path: /media/alex/SSD/rnn_cache.pth


training:
  lr: 1e-4
  
  batch_size: 512
  train_size: 0.9
  val_size: 0.1
  n_grad_accum_steps: 1
  grad_norm: 1.0
  fp16: False

  n_local_steps: 2000
  model_update:
    n_steps: 2000
    type: hard
    rate: 0.1

  output_folder: ../gym_output
  
  save:
    model_name: lunar_lander
    save_every_n_step: 20
    n_last_steps: 3
    target_metric: reward
    target_op: '>'
    
  eps_greedy:
    eps_from: 0.6
    eps_to: 0.05
    n_epochs_of_decays: 300
