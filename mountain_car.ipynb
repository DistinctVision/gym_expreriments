{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import imageio\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import gymnasium as gym\n",
    "\n",
    "camera = dict(\n",
    "    up=dict(x=0, y=0, z=1),\n",
    "    center=dict(x=0, y=0, z=0),\n",
    "    eye=dict(x=0.25, y=-2.0, z=2.0)\n",
    ")\n",
    "env = gym.make('MountainCar-v0')\n",
    "obs_space: gym.spaces.Box = env.observation_space\n",
    "\n",
    "discrete_positions = np.linspace(obs_space.low[0], obs_space.high[0], num=40)\n",
    "discrete_vels = np.linspace(obs_space.low[1], obs_space.high[1], num=40)\n",
    "actions = [0, 1, 2]\n",
    "\n",
    "def draw_v_function_and_policy(title: str, q_array: np.ndarray) -> go.Figure:\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        shared_xaxes=False,\n",
    "        specs=[[{'type': 'surface'}, {'type': 'surface'}]],\n",
    "        subplot_titles=(\"Value function\", \"Policy\"))\n",
    "    \n",
    "    v_data = q_array.max(axis=2)\n",
    "    policy_data = q_array.argmax(axis=2)\n",
    "\n",
    "    fig.add_trace(go.Surface(x=discrete_positions, y=discrete_vels, z=v_data, colorscale='YlGnBu'), col=1, row=1)\n",
    "    fig.add_trace(go.Surface(x=discrete_positions, y=discrete_vels, z=policy_data, colorscale='YlGnBu'), col=2, row=1)\n",
    "    fig.layout.scene1.camera=camera\n",
    "    fig.layout.scene2.camera=camera\n",
    "    fig.update_layout(scene_camera=camera, title=title,\n",
    "                      margin=dict(r=25, l=25, b=10, t=80),\n",
    "                      width=750,\n",
    "                      showlegend=False)\n",
    "    fig.update_scenes(xaxis_title_text='position ',  \n",
    "                      yaxis_title_text='velocity')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:32: DeprecationWarning:\n",
      "\n",
      "Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "\n",
      "  0%|          | 0/200000 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:85: DeprecationWarning:\n",
      "\n",
      "Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "\n",
      "Reward: -119.32, best reward: -107.98, eps: 0.01: 100%|██████████| 200000/200000 [45:51<00:00, 72.69it/s]  \n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (750, 500) to (752, 512) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import gymnasium as gym\n",
    "from tqdm import tqdm\n",
    "\n",
    "env = gym.make('MountainCar-v0')\n",
    "obs_space: gym.spaces.Box = env.observation_space\n",
    "\n",
    "Q = np.zeros((discrete_positions.shape[0], discrete_vels.shape[0], 3), dtype=float)\n",
    "Q_size = np.array(list(Q.shape[:2]), dtype=float)\n",
    "\n",
    "n_episodes = 200000\n",
    "eps_from = 0.6\n",
    "eps_to = 1e-2\n",
    "lr = 2e-2\n",
    "discount_rate = 0.99\n",
    "\n",
    "temp_dir = Path('tmp')\n",
    "if temp_dir.exists():\n",
    "    shutil.rmtree(temp_dir)\n",
    "temp_dir.mkdir()\n",
    "images = []\n",
    "\n",
    "last_rewards = deque(maxlen=100)\n",
    "best_reward = -1e10\n",
    "best_Q = None\n",
    "\n",
    "fig = draw_v_function_and_policy('Start', Q)\n",
    "image_path = temp_dir / 'begin.png'\n",
    "fig.write_image(image_path)\n",
    "images.append(imageio.imread(image_path))\n",
    "\n",
    "ep_reward = 0\n",
    "progress_bar = tqdm(range(n_episodes))\n",
    "for ep_idx in progress_bar:\n",
    "    t_eps_greedy = min(max((ep_idx - 10000) / n_episodes, 0.0), 1.0)\n",
    "    eps_greedy = eps_from * math.exp(math.log(eps_to / eps_from) * t_eps_greedy)\n",
    "    # eps_greedy = eps_from + (eps_to - eps_from) * (ep_idx / n_episodes)\n",
    "    # eps_greedy = 0.5\n",
    "    \n",
    "    done = False\n",
    "    ep_reward = 0\n",
    "    state, info = env.reset()\n",
    "    discrete_state = np.round((state - obs_space.low) * (Q_size / (obs_space.high - obs_space.low)))\n",
    "    discrete_state = discrete_state.astype(int)\n",
    "    \n",
    "    while not done:\n",
    "        if np.random.uniform(0, 1) < eps_greedy:\n",
    "            action = np.random.choice(actions)\n",
    "        else:\n",
    "            action = Q[discrete_state[0], discrete_state[1]].argmax()\n",
    "            \n",
    "        next_state, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        \n",
    "        next_discrete_state = np.round((next_state - obs_space.low) * (Q_size / (obs_space.high - obs_space.low)))\n",
    "        next_discrete_state = next_discrete_state.astype(int)\n",
    "        \n",
    "        if terminated:\n",
    "            td_target = reward\n",
    "        else:\n",
    "            td_target = reward + Q[next_discrete_state[0], next_discrete_state[1]].max() * discount_rate\n",
    "        td_error = td_target - Q[discrete_state[0], discrete_state[1], action]\n",
    "        Q[discrete_state[0], discrete_state[1], action] += td_error * lr\n",
    "\n",
    "        ep_reward += reward\n",
    "        \n",
    "        state = next_state\n",
    "        discrete_state = next_discrete_state\n",
    "    \n",
    "    last_rewards.append(ep_reward)\n",
    "    \n",
    "    mean_reward = sum(last_rewards) / len(last_rewards)\n",
    "    if mean_reward > best_reward:\n",
    "        best_reward = mean_reward\n",
    "        best_Q = Q.copy()\n",
    "    if ep_idx % 500 == 0:\n",
    "        ep_name = str(ep_idx) if ep_idx > 0 else '1'\n",
    "        title = f'Episode {ep_name}, eps: {eps_greedy:.2f}, mean reward: {mean_reward:.2f}, '\\\n",
    "            f'best reward: {best_reward:.2f}'\n",
    "        fig = draw_v_function_and_policy(title, Q)\n",
    "        image_path = temp_dir / f'episode_{ep_name}.png'\n",
    "        fig.write_image(image_path)\n",
    "        images.append(imageio.imread(image_path))\n",
    "        \n",
    "    progress_bar.set_description(f'Reward: {mean_reward:.2f}, best reward: {best_reward:.2f}, eps: {eps_greedy:.2f}')\n",
    "\n",
    "env.close()\n",
    "imageio.mimsave('MountainCar_sarsa.mp4', images, fps=10)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: -107.98\n"
     ]
    }
   ],
   "source": [
    "last_rewards.clear()\n",
    "\n",
    "for ep_idx in range(100):\n",
    "    done = False\n",
    "    ep_reward = 0\n",
    "    state, info = env.reset()\n",
    "    discrete_state = np.round((state - obs_space.low) * (Q_size / (obs_space.high - obs_space.low)))\n",
    "    discrete_state = discrete_state.astype(int)\n",
    "    \n",
    "    while not done:\n",
    "        action = best_Q[discrete_state[0], discrete_state[1]].argmax()\n",
    "            \n",
    "        next_state, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        \n",
    "        next_discrete_state = np.round((next_state - obs_space.low) * (Q_size / (obs_space.high - obs_space.low)))\n",
    "        next_discrete_state = next_discrete_state.astype(int)\n",
    "        \n",
    "        state = next_state\n",
    "        discrete_state = next_discrete_state\n",
    "    \n",
    "    last_rewards.append(ep_reward)\n",
    "print(f'Mean reward: {best_reward}')\n",
    "\n",
    "np.save('best_Q.npy', best_Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: -96.00\n",
      "Mean reward: -102.50\n",
      "Mean reward: -106.33\n",
      "Mean reward: -107.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (600, 400) to (608, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: -108.20\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from collections import deque\n",
    "import shutil\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import imageio\n",
    "\n",
    "env = gym.make('MountainCar-v0', render_mode='rgb_array')\n",
    "obs_space: gym.spaces.Box = env.observation_space\n",
    "\n",
    "Q: np.ndarray = np.load('best_Q.npy')\n",
    "Q_size = np.array(list(Q.shape[:2]), dtype=float)\n",
    "\n",
    "temp_dir = Path('tmp')\n",
    "if temp_dir.exists():\n",
    "    shutil.rmtree(temp_dir)\n",
    "temp_dir.mkdir()\n",
    "images = []\n",
    "\n",
    "last_rewards = deque(maxlen=100)\n",
    "best_reward = -1e10\n",
    "\n",
    "for _ in range(5):\n",
    "    done = False\n",
    "    ep_reward = 0\n",
    "    state, info = env.reset()\n",
    "    discrete_state = np.round((state - obs_space.low) * (Q_size / (obs_space.high - obs_space.low)))\n",
    "    discrete_state = discrete_state.astype(int)\n",
    "    \n",
    "    rgb_frame = env.render()\n",
    "    images.append(rgb_frame)\n",
    "    while not done:\n",
    "        action = Q[discrete_state[0], discrete_state[1]].argmax()\n",
    "            \n",
    "        next_state, reward, terminated, truncated, info = env.step(action)\n",
    "        rgb_frame = env.render()\n",
    "        images.append(rgb_frame)\n",
    "        \n",
    "        done = terminated or truncated\n",
    "        \n",
    "        next_discrete_state = np.round((next_state - obs_space.low) * (Q_size / (obs_space.high - obs_space.low)))\n",
    "        next_discrete_state = next_discrete_state.astype(int)\n",
    "        \n",
    "        state = next_state\n",
    "        discrete_state = next_discrete_state\n",
    "        \n",
    "        ep_reward += reward\n",
    "    \n",
    "    last_rewards.append(ep_reward)\n",
    "    mean_reward = sum(last_rewards) / len(last_rewards)\n",
    "    print(f'Mean reward: {mean_reward:.2f}')\n",
    "    \n",
    "env.close()\n",
    "imageio.mimsave('MountainCar_best_policy.mp4', images, fps=30)    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
